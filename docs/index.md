# CultureKit Documentation

> **Beta Status**: CultureKit is currently in beta testing. Features, APIs, and documentation may change without notice.

Welcome to the CultureKit documentation. This toolkit helps you evaluate the cultural dimensions of MLX large language models (LLMs) on the CD Eval benchmark.

## Getting Started

- [Installation](../README.md#installation) - How to install CultureKit
- [Quick Start](../README.md#quick-start) - Quick start guide
- [Environment Setup](environment_setup.md) - How to set up your environment

## Model Support

- [Model Formats and Configurations](model_formats.md) - Detailed information about supported model formats
- [Model Evaluation](model_eval.md) - Guide for evaluating models

## Key Concepts

### CD Eval Benchmark

The CD Eval benchmark assesses language models across various cultural dimensions, including:

- Cultural values and norms
- Social practices and customs
- Language use and communication styles
- Religious and philosophical perspectives
- Historical and geopolitical contexts

### Supported Model Types

CultureKit supports multiple model types:

- **MLX Models**: Optimized for Apple Silicon hardware
- **Azure OpenAI Models**: Models hosted on Azure OpenAI service
- **Azure Foundry Models**: Custom models on Azure AI Foundry service

### Prompt Templates

The toolkit uses various prompt templates to evaluate models, including:

- Direct question prompts
- Perspective-taking prompts
- Comparative analysis prompts
- Scenario-based prompts
